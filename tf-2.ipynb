{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The TensorFlow Keras API (tf.keras)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a linear regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.arange(10).reshape((10,1))\n",
    "X_2 = np.random.uniform(0, 10, 10).reshape((10,1))\n",
    "y_train = np.array([1.0, 1.3, 3.1,\n",
    "                    2.0, 5.0, 6.3,\n",
    "                    6.6, 7.4, 8.0,\n",
    "                    9.0])\n",
    "\n",
    "\n",
    "plt.plot(X_train, y_train, 'o', markersize=10)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_norm = (X_train - np.mean(X_train))/np.std(X_train)\n",
    "X_2 = (X_2 - np.mean(X_2))/ np.std(X_2)\n",
    "ds_train_orig = tf.data.Dataset.from_tensor_slices(\n",
    "    (tf.cast(np.hstack((X_train_norm, X_2)), tf.float32),\n",
    "     tf.cast(y_train, tf.float32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.hstack((X_train_norm, X_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyModel(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.w = tf.Variable(0.0, name='weight')\n",
    "        self.b = tf.Variable(0.0, name='bias')\n",
    "\n",
    "    def call(self, x):\n",
    "        return self.w*x + self.b\n",
    "\n",
    "\n",
    "model = MyModel()\n",
    "\n",
    "model.build(input_shape=(None, 1))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(y_true, y_pred):\n",
    "    return tf.reduce_mean(tf.square(y_true - y_pred))\n",
    "\n",
    "\n",
    "## testing the function:\n",
    "yt = tf.convert_to_tensor([1.0])\n",
    "yp = tf.convert_to_tensor([1.5])\n",
    "\n",
    "loss_fn(yt, yp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, inputs, outputs, learning_rate):\n",
    "    with tf.GradientTape() as tape:\n",
    "        current_loss = loss_fn(model(inputs), outputs)\n",
    "    dW, db = tape.gradient(current_loss, [model.w, model.b])\n",
    "    model.w.assign_sub(learning_rate * dW)\n",
    "    model.b.assign_sub(learning_rate * db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "num_epochs = 200\n",
    "log_steps = 100\n",
    "learning_rate = 0.001\n",
    "batch_size = 1\n",
    "steps_per_epoch = int(np.ceil(len(y_train) / batch_size))\n",
    "\n",
    "\n",
    "ds_train = ds_train_orig.shuffle(buffer_size=len(y_train))\n",
    "ds_train = ds_train.repeat(count=None)\n",
    "ds_train = ds_train.batch(1)\n",
    "\n",
    "Ws, bs = [], []\n",
    "\n",
    "for i, batch in enumerate(ds_train):\n",
    "    if i >= steps_per_epoch * num_epochs:\n",
    "        break\n",
    "    Ws.append(model.w.numpy())\n",
    "    bs.append(model.b.numpy())\n",
    "\n",
    "    bx, by = batch\n",
    "    loss_val = loss_fn(model(bx), by)\n",
    "\n",
    "    train(model, bx, by, learning_rate=learning_rate)\n",
    "    if i%log_steps==0:\n",
    "        print('Epoch {:4d} Step {:2d} Loss {:6.4f}'.format(\n",
    "              int(i/steps_per_epoch), i, loss_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Final Parameters:', model.w.numpy(), model.b.numpy())\n",
    "\n",
    "\n",
    "X_test = np.linspace(0, 9, num=100).reshape(-1, 1)\n",
    "X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n",
    "\n",
    "y_pred = model(tf.cast(X_test_norm, dtype=tf.float32))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(X_train_norm, y_train, 'o', markersize=10)\n",
    "plt.plot(X_test_norm, y_pred, '--', lw=3)\n",
    "plt.legend(['Training examples', 'Linear Reg.'], fontsize=15)\n",
    "ax.set_xlabel('x', size=15)\n",
    "ax.set_ylabel('y', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(Ws, lw=3)\n",
    "plt.plot(bs, lw=3)\n",
    "plt.legend(['Weight w', 'Bias unit b'], fontsize=15)\n",
    "ax.set_xlabel('Iteration', size=15)\n",
    "ax.set_ylabel('Value', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "#plt.savefig('ch13-linreg-1.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model training via the .compile() and .fit() methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "model = MyModel()\n",
    "#model.build((None, 1))\n",
    "\n",
    "model.compile(optimizer='sgd', \n",
    "              loss=loss_fn,\n",
    "              metrics=['mae', 'mse'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(X_train_norm, y_train, \n",
    "          epochs=num_epochs, batch_size=batch_size,\n",
    "          verbose=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.w.numpy(), model.b.numpy())\n",
    "\n",
    "\n",
    "X_test = np.linspace(0, 9, num=100).reshape(-1, 1)\n",
    "X_test_norm = (X_test - np.mean(X_train)) / np.std(X_train)\n",
    "\n",
    "y_pred = model(tf.cast(X_test_norm, dtype=tf.float32))\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(13, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "plt.plot(X_train_norm, y_train, 'o', markersize=10)\n",
    "plt.plot(X_test_norm, y_pred, '--', lw=3)\n",
    "plt.legend(['Training Samples', 'Linear Regression'], fontsize=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "plt.plot(Ws, lw=3)\n",
    "plt.plot(bs, lw=3)\n",
    "plt.legend(['W', 'bias'], fontsize=15)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building a multilayer perceptron for classifying flowers in the Iris dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "\n",
    "\n",
    "iris, iris_info = tfds.load('iris', with_info=True)\n",
    "\n",
    "print(iris_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "ds_orig = iris['train']\n",
    "ds_orig = ds_orig.shuffle(150, reshuffle_each_iteration=False)\n",
    "\n",
    "print(next(iter(ds_orig)))\n",
    "\n",
    "ds_train_orig = ds_orig.take(100)\n",
    "ds_test = ds_orig.skip(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## checking the number of examples:\n",
    "\n",
    "n = 0\n",
    "for example in ds_train_orig:\n",
    "    n += 1\n",
    "print(n)\n",
    "\n",
    "\n",
    "n = 0\n",
    "for example in ds_test:\n",
    "    n += 1\n",
    "print(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train_orig = ds_train_orig.map(\n",
    "    lambda x: (x['features'], x['label']))\n",
    "\n",
    "ds_test = ds_test.map(\n",
    "    lambda x: (x['features'], x['label']))\n",
    "\n",
    "next(iter(ds_train_orig))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(16, activation='sigmoid', \n",
    "                          name='fc1', input_shape=(4,)),\n",
    "    tf.keras.layers.Dense(3, name='fc2', activation='softmax')])\n",
    "\n",
    "iris_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model.compile(optimizer='adam',\n",
    "                   loss='sparse_categorical_crossentropy',\n",
    "                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "training_size = 100\n",
    "batch_size = 2\n",
    "steps_per_epoch = np.ceil(training_size / batch_size)\n",
    "\n",
    "ds_train = ds_train_orig.shuffle(buffer_size=training_size)\n",
    "ds_train = ds_train.repeat()\n",
    "ds_train = ds_train.batch(batch_size=batch_size)\n",
    "ds_train = ds_train.prefetch(buffer_size=1000)\n",
    "\n",
    "\n",
    "history = iris_model.fit(ds_train, epochs=num_epochs,\n",
    "                         steps_per_epoch=steps_per_epoch, \n",
    "                         verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist = history.history\n",
    "\n",
    "fig = plt.figure(figsize=(12, 5))\n",
    "ax = fig.add_subplot(1, 2, 1)\n",
    "ax.plot(hist['loss'], lw=3)\n",
    "ax.set_title('Training loss', size=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "\n",
    "ax = fig.add_subplot(1, 2, 2)\n",
    "ax.plot(hist['accuracy'], lw=3)\n",
    "ax.set_title('Training accuracy', size=15)\n",
    "ax.set_xlabel('Epoch', size=15)\n",
    "ax.tick_params(axis='both', which='major', labelsize=15)\n",
    "plt.tight_layout()\n",
    "#plt.savefig('ch13-cls-learning-curve.pdf')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the trained model on the test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = iris_model.evaluate(ds_test.batch(50), verbose=0)\n",
    "print('Test loss: {:.4f}   Test Acc.: {:.4f}'.format(*results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving and reloading the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model.save('iris-classifier.h5', \n",
    "                overwrite=True,\n",
    "                include_optimizer=True,\n",
    "                save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model_new = tf.keras.models.load_model('iris-classifier.h5')\n",
    "\n",
    "iris_model_new.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = iris_model_new.evaluate(ds_test.batch(50), verbose=0)\n",
    "print('Test loss: {:.4f}   Test Acc.: {:.4f}'.format(*results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_train = []\n",
    "for i,item in enumerate(ds_train_orig):\n",
    "    labels_train.append(item[1].numpy())\n",
    "    \n",
    "labels_test = []\n",
    "for i,item in enumerate(ds_test):\n",
    "    labels_test.append(item[1].numpy())\n",
    "print('Training Set: ',len(labels_train), 'Test Set: ', len(labels_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris_model_new.to_json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing activation functions for multilayer neural networks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic function recap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "X = np.array([1, 1.4, 2.5]) ## first value must be 1\n",
    "w = np.array([0.4, 0.3, 0.5])\n",
    "\n",
    "def net_input(X, w):\n",
    "    return np.dot(X, w)\n",
    "\n",
    "def logistic(z):\n",
    "    return 1.0 / (1.0 + np.exp(-z))\n",
    "\n",
    "def logistic_activation(X, w):\n",
    "    z = net_input(X, w)\n",
    "    return logistic(z)\n",
    "\n",
    "print('P(y=1|x) = %.3f' % logistic_activation(X, w)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# W : array with shape = (n_output_units, n_hidden_units+1)\n",
    "# note that the first column are the bias units\n",
    "\n",
    "W = np.array([[1.1, 1.2, 0.8, 0.4],\n",
    "              [0.2, 0.4, 1.0, 0.2],\n",
    "              [0.6, 1.5, 1.2, 0.7]])\n",
    "\n",
    "# A : data array with shape = (n_hidden_units + 1, n_samples)\n",
    "# note that the first column of this array must be 1\n",
    "\n",
    "A = np.array([[1, 0.1, 0.4, 0.6]])\n",
    "Z = np.dot(W, A[0])\n",
    "y_probas = logistic(Z)\n",
    "print('Net Input: \\n', Z)\n",
    "\n",
    "print('Output Units:\\n', y_probas) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_class = np.argmax(Z, axis=0)\n",
    "print('Predicted class label: %d' % y_class) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimating class probabilities in multiclass classification via the softmax function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(z):\n",
    "    return np.exp(z) / np.sum(np.exp(z))\n",
    "\n",
    "y_probas = softmax(Z)\n",
    "print('Probabilities:\\n', y_probas)\n",
    "\n",
    "np.sum(y_probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "Z_tensor = tf.expand_dims(Z, axis=0)\n",
    "tf.keras.activations.softmax(Z_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadening the output spectrum using a hyperbolic tangent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "def tanh(z):\n",
    "    e_p = np.exp(z)\n",
    "    e_m = np.exp(-z)\n",
    "    return (e_p - e_m) / (e_p + e_m)\n",
    "\n",
    "z = np.arange(-5, 5, 0.005)\n",
    "log_act = logistic(z)\n",
    "tanh_act = tanh(z)\n",
    "plt.ylim([-1.5, 1.5])\n",
    "plt.xlabel('Net input $z$')\n",
    "plt.ylabel('Activation $\\phi(z)$')\n",
    "plt.axhline(1, color='black', linestyle=':')\n",
    "plt.axhline(0.5, color='black', linestyle=':')\n",
    "plt.axhline(0, color='black', linestyle=':')\n",
    "plt.axhline(-0.5, color='black', linestyle=':')\n",
    "plt.axhline(-1, color='black', linestyle=':')\n",
    "plt.plot(z, tanh_act,\n",
    "    linewidth=3, linestyle='--',\n",
    "    label='Tanh')\n",
    "plt.plot(z, log_act,\n",
    "    linewidth=3,\n",
    "    label='Logistic')\n",
    "plt.legend(loc='lower right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "tf.keras.activations.tanh(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import expit\n",
    "\n",
    "expit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.activations.sigmoid(z)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
