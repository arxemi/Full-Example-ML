{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating tensors in TensorFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "a = np.array([1, 2, 3], dtype=np.int32)\n",
    "b = [4, 5, 6]\n",
    "\n",
    "t_a = tf.convert_to_tensor(a)\n",
    "t_b = tf.convert_to_tensor(b)\n",
    "\n",
    "print(t_a)\n",
    "print(t_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.is_tensor(a), tf.is_tensor(t_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ones = tf.ones((2, 3))\n",
    "\n",
    "t_ones.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_ones.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "const_tensor = tf.constant([1.2, 5, np.pi], dtype=tf.float32)\n",
    "\n",
    "print(const_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manipulating the data type and shape of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_a_new = tf.cast(t_a, tf.int64)\n",
    "\n",
    "print(t_a_new.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.random.uniform(shape=(3, 5))\n",
    "\n",
    "t_tr = tf.transpose(t)\n",
    "print(t.shape, ' --> ', t_tr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.zeros((30,))\n",
    "\n",
    "t_reshape = tf.reshape(t, shape=(5, 6))\n",
    "\n",
    "print(t_reshape.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tf.zeros((1, 2, 1, 4, 1))\n",
    "\n",
    "t_sqz = tf.squeeze(t, axis=(2, 4)) # rimozione delle dimensioni 2 e 4\n",
    "\n",
    "print(t.shape, ' --> ', t_sqz.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying mathematical operations to tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "t1 = tf.random.uniform(shape=(5, 2), \n",
    "                       minval=-1.0,\n",
    "                       maxval=1.0)\n",
    "\n",
    "t2 = tf.random.normal(shape=(5, 2), \n",
    "                      mean=0.0,\n",
    "                      stddev=1.0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t3 = tf.multiply(t1, t2).numpy()\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t4 = tf.math.reduce_mean(t1, axis=0)\n",
    "\n",
    "print(t4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t5 = tf.linalg.matmul(t1, t2, transpose_b=True)\n",
    "\n",
    "print(t5.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t6 = tf.linalg.matmul(t1, t2, transpose_a=True)\n",
    "\n",
    "print(t6.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_t1 = tf.norm(t1, ord=2, axis=1).numpy()\n",
    "\n",
    "print(norm_t1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum(np.square(t1), axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split, stack, and concatenate tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "t = tf.random.uniform((6,))\n",
    "\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, 3)\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "t = tf.random.uniform((5,))\n",
    "\n",
    "print(t.numpy())\n",
    "\n",
    "t_splits = tf.split(t, num_or_size_splits=[3, 2])\n",
    "\n",
    "[item.numpy() for item in t_splits]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((2,))\n",
    "\n",
    "C = tf.concat([A, B], axis=0)\n",
    "print(C.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = tf.ones((3,))\n",
    "B = tf.zeros((3,))\n",
    "\n",
    "S = tf.stack([A, B], axis=1)\n",
    "print(S.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building input pipelines using tf.data: The TensorFlow Dataset API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a TensorFlow Dataset from existing tensors "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [1.2, 3.4, 7.5, 4.1, 5.0, 1.0]\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices(a)\n",
    "\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in ds:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_batch = ds.batch(3)\n",
    "\n",
    "for i, elem in enumerate(ds_batch, 1):\n",
    "    print('batch {}:'.format(i), elem.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining two tensors into a joint dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "t_x = tf.random.uniform([4, 3], dtype=tf.float32)\n",
    "t_y = tf.range(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_x = tf.data.Dataset.from_tensor_slices(t_x)\n",
    "ds_y = tf.data.Dataset.from_tensor_slices(t_y)\n",
    "    \n",
    "ds_joint = tf.data.Dataset.zip((ds_x, ds_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print('  x: ', example[0].numpy(), \n",
    "          '  y: ', example[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## method 2:\n",
    "ds_joint = tf.data.Dataset.from_tensor_slices((t_x, t_y))\n",
    "\n",
    "for example in ds_joint:\n",
    "    print('  x: ', example[0].numpy(), \n",
    "          '  y: ', example[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_trans = ds_joint.map(lambda x, y: (x*2-1.0, y))\n",
    "\n",
    "for example in ds_trans:\n",
    "    print('  x: ', example[0].numpy(), \n",
    "          '  y: ', example[1].numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle, batch, and repeat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "ds = ds_joint.shuffle(buffer_size=len(t_x))\n",
    "\n",
    "for example in ds:\n",
    "    print('  x: ', example[0].numpy(), \n",
    "          '  y: ', example[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_joint.batch(batch_size=3,\n",
    "                    drop_remainder=False)\n",
    "\n",
    "batch_x, batch_y = next(iter(ds))\n",
    "\n",
    "print('Batch-x: \\n', batch_x.numpy())\n",
    "\n",
    "print('Batch-y:   ', batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_joint.batch(3).repeat(count=2)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = ds_joint.repeat(count=2).batch(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 1: shuffle -> batch -> repeat\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 1: shuffle -> batch -> repeat\n",
    "ds = ds_joint.shuffle(4).batch(2).repeat(20)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 2: batch -> shuffle -> repeat\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(3)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.random.set_seed(1)\n",
    "\n",
    "## Order 2: batch -> shuffle -> repeat\n",
    "ds = ds_joint.batch(2).shuffle(4).repeat(20)\n",
    "\n",
    "for i,(batch_x, batch_y) in enumerate(ds):\n",
    "    print(i, batch_x.shape, batch_y.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a dataset from files on your local storage disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "imgdir_path = pathlib.Path('cat_dog_images')\n",
    "\n",
    "file_list = sorted([str(path) for path in imgdir_path.glob('*.jpg')])\n",
    "\n",
    "print(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i,file in enumerate(file_list):\n",
    "    img_raw = tf.io.read_file(file)\n",
    "    img = tf.image.decode_image(img_raw)\n",
    "    print('Image shape: ', img.shape)\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(img)\n",
    "    ax.set_title(os.path.basename(file), size=15)\n",
    "    \n",
    "# plt.savefig('ch13-catdot-examples.pdf')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [1 if 'dog' in os.path.basename(file) else 0\n",
    "          for file in file_list]\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_files_labels = tf.data.Dataset.from_tensor_slices(\n",
    "    (file_list, labels))\n",
    "\n",
    "for item in ds_files_labels:\n",
    "    print(item[0].numpy(), item[1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_preprocess(path, label):\n",
    "    image = tf.io.read_file(path)\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = tf.image.resize(image, [img_height, img_width])\n",
    "    image /= 255.0\n",
    "\n",
    "    return image, label\n",
    "\n",
    "img_width, img_height = 120, 80\n",
    "\n",
    "ds_images_labels = ds_files_labels.map(load_and_preprocess)\n",
    "\n",
    "fig = plt.figure(figsize=(10, 5))\n",
    "for i,example in enumerate(ds_images_labels):\n",
    "    print(example[0].shape, example[1].numpy())\n",
    "    ax = fig.add_subplot(2, 3, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(example[0])\n",
    "    ax.set_title('{}'.format(example[1].numpy()), \n",
    "                 size=15)\n",
    "    \n",
    "plt.tight_layout()\n",
    "#plt.savefig('ch13-catdog-dataset.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetching available datasets from the tensorflow_datasets library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install tensorflow-datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "\n",
    "print(len(tfds.list_builders()))\n",
    "print(tfds.list_builders()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run this to see the full list:\n",
    "tfds.list_builders()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fetching CelebA dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "celeba_bldr = tfds.builder('celeb_a')\n",
    "\n",
    "print(celeba_bldr.info.features)\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.features.keys())\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.features['image'])\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.features['attributes'].keys())\n",
    "print('\\n', 30*\"=\", '\\n')\n",
    "print(celeba_bldr.info.citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the data, prepare it, and write it to disk\n",
    "celeba_bldr.download_and_prepare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from disk as tf.data.Datasets\n",
    "datasets = celeba_bldr.as_dataset(shuffle_files=False)\n",
    "\n",
    "datasets.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "ds_train = datasets['train']\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "\n",
    "example = next(iter(ds_train))\n",
    "print(type(example))\n",
    "print(example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.map(lambda item: \n",
    "     (item['image'], tf.cast(item['attributes']['Male'], tf.int32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = ds_train.batch(18)\n",
    "images, labels = next(iter(ds_train))\n",
    "\n",
    "print(images.shape, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12, 8))\n",
    "for i,(image,label) in enumerate(zip(images, labels)):\n",
    "    ax = fig.add_subplot(3, 6, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image)\n",
    "    ax.set_title('{}'.format(label), size=15)\n",
    "    \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alternative ways for loading a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist, mnist_info = tfds.load('mnist', with_info=True,\n",
    "                              shuffle_files=False)\n",
    "\n",
    "print(mnist_info)\n",
    "\n",
    "print(mnist.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train = mnist['train']\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "\n",
    "ds_train = ds_train.map(lambda item: \n",
    "     (item['image'], item['label']))\n",
    "\n",
    "ds_train = ds_train.batch(10)\n",
    "batch = next(iter(ds_train))\n",
    "print(batch[0].shape, batch[1])\n",
    "\n",
    "fig = plt.figure(figsize=(15, 6))\n",
    "for i,(image,label) in enumerate(zip(batch[0], batch[1])):\n",
    "    ax = fig.add_subplot(2, 5, i+1)\n",
    "    ax.set_xticks([]); ax.set_yticks([])\n",
    "    ax.imshow(image[:, :, 0], cmap='gray_r')\n",
    "    ax.set_title('{}'.format(label), size=15)\n",
    "    \n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  },
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
